{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476adf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn  as nn \n",
    "import torch.optim  as optim\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot  as plt \n",
    "import os \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393b6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 配置参数\n",
    "# CONTENT_IMG = \"input.jpg\"   # 当前目录下的输入图片\n",
    "# OUTPUT_DIR = \".\"  # 输出目录 \n",
    "# STYLE_IMG = \"style.png\"   # 风格图片\n",
    "# IMAGE_SIZE = 512  # 图像尺寸\n",
    "# NUM_STEPS = 5000  # 迭代次数\n",
    "# STYLE_WEIGHT = 1  # 风格权重\n",
    "# CONTENT_WEIGHT = 1  # 内容权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f61346a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 提取特征\n",
    "# def get_features(image, model, layers):\n",
    "#     features = {}\n",
    "#     x = image\n",
    "#     for idx, layer in enumerate(model):\n",
    "#         x = layer(x)\n",
    "#         if str(idx) in layers:\n",
    "#             features[str(idx)] = x\n",
    "#     return features\n",
    " \n",
    "# # 计算Gram矩阵（风格特征）\n",
    "# def gram_matrix(tensor):\n",
    "#     _, c, h, w = tensor.size() \n",
    "#     tensor = tensor.view(c,  h * w)\n",
    "#     return torch.mm(tensor,  tensor.t())\n",
    "\n",
    "# # 图像预处理转换 \n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.Resize(IMAGE_SIZE),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    " \n",
    "# # 反标准化转换 \n",
    "# def deprocess(tensor):\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Normalize(mean=[0, 0, 0], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "#         transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
    "#         transforms.ToPILImage()\n",
    "#     ])\n",
    "#     return transform(tensor)\n",
    " \n",
    "# # 加载图像\n",
    "# def load_image(image_path):\n",
    "#     image = Image.open(image_path).convert('RGB') \n",
    "#     image = preprocess(image).unsqueeze(0)\n",
    "#     return image.to(device,  torch.float) \n",
    " \n",
    "# # 保存图像\n",
    "# def save_image(tensor, filename):\n",
    "#     image = deprocess(tensor.squeeze(0).cpu().clone()) \n",
    "#     image.save(os.path.join(OUTPUT_DIR,  filename))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e002db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 创建输出目录\n",
    "# os.makedirs(OUTPUT_DIR,  exist_ok=True)\n",
    "\n",
    "# # 设备配置 \n",
    "# device = torch.device(\"cuda\"  if torch.cuda.is_available()  else \"cpu\")\n",
    "# print(f\"使用设备: {device}\")\n",
    " \n",
    "# # 加载轻量级SqueezeNet模型 [6]()\n",
    "# model = models.squeezenet1_1(pretrained=True).features.to(device).eval() \n",
    " \n",
    "# # 冻结模型参数\n",
    "# for param in model.parameters(): \n",
    "#     param.requires_grad  = False\n",
    " \n",
    "# # 加载内容图像和风格图像 \n",
    "# content_img = load_image(CONTENT_IMG)\n",
    "# style_img = load_image(STYLE_IMG)\n",
    " \n",
    "# # 创建目标图像（初始化为内容图像）\n",
    "# input_img = content_img.clone().requires_grad_(True) \n",
    " \n",
    "# # 定义内容层和风格层\n",
    "# content_layers = ['12']  # SqueezeNet中的关键特征层 \n",
    "# style_layers = ['0', '3', '6', '8', '10']  # 多尺度风格特征层 \n",
    "\n",
    "# # 优化器配置 \n",
    "# optimizer = optim.LBFGS([input_img])\n",
    " \n",
    "# # 训练循环 \n",
    "# step = [0]\n",
    "# while step[0] <= NUM_STEPS:\n",
    "    \n",
    "#     def closure():\n",
    "#         # 梯度清零\n",
    "#         optimizer.zero_grad() \n",
    "        \n",
    "#         # 获取特征\n",
    "#         content_features = get_features(content_img, model, content_layers)\n",
    "#         style_features = get_features(style_img, model, style_layers)\n",
    "#         input_features = get_features(input_img, model, set(content_layers + style_layers))\n",
    "        \n",
    "#         # 计算内容损失\n",
    "#         content_loss = 0 \n",
    "#         for layer in content_layers:\n",
    "#             content_loss += torch.mean((input_features[layer]  - content_features[layer])**2)\n",
    "        \n",
    "#         # 计算风格损失\n",
    "#         style_loss = 0 \n",
    "#         for layer in style_layers:\n",
    "#             input_gram = gram_matrix(input_features[layer])\n",
    "#             style_gram = gram_matrix(style_features[layer])\n",
    "#             norm_factor = input_features[layer].numel()  # 或 C * H * W\n",
    "#             style_loss += torch.mean((input_gram  - style_gram)**2) / norm_factor\n",
    "        \n",
    "#         # 总损失\n",
    "#         total_loss = CONTENT_WEIGHT * content_loss + STYLE_WEIGHT * style_loss\n",
    "        \n",
    "#         # 反向传播\n",
    "#         total_loss.backward() \n",
    "        \n",
    "#         # 每50步保存进度\n",
    "#         if step[0] % 1000 == 0:\n",
    "#             print(f\"Step {step[0]}: Content Loss: {content_loss.item():.4f},  Style Loss: {style_loss.item():.4f}\") \n",
    "#             save_image(input_img, f\"output_step_{step[0]}.jpg\")\n",
    "        \n",
    "#         step[0] += 1\n",
    "#         return total_loss \n",
    "    \n",
    "#     optimizer.step(closure) \n",
    " \n",
    "# # 保存最终结果\n",
    "# save_image(input_img, \"pic.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae049b74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "未检测到人脸2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 88\u001b[0m\n\u001b[0;32m     86\u001b[0m img1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m     87\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle.png\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m---> 88\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mface_fusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,  result)\n",
      "Cell \u001b[1;32mIn[3], line 63\u001b[0m, in \u001b[0;36mface_fusion\u001b[1;34m(img1, img2, alpha)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m未检测到人脸1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pts2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m未检测到人脸2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# 2. 三角剖分 \u001b[39;00m\n\u001b[0;32m     66\u001b[0m triangles \u001b[38;5;241m=\u001b[39m delaunay_triangulation(pts1, img1\u001b[38;5;241m.\u001b[39mshape) \n",
      "\u001b[1;31mValueError\u001b[0m: 未检测到人脸2"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import dlib\n",
    "# import numpy as np \n",
    " \n",
    "# # 初始化dlib人脸检测器和特征点预测器 \n",
    "# detector = dlib.get_frontal_face_detector() \n",
    "# predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")   \n",
    " \n",
    "# def get_landmarks(img):\n",
    "#     \"\"\"提取人脸68特征点+12个辅助点（图像四角、肩膀等）[11]()\"\"\"\n",
    "#     gray = cv2.cvtColor(img,  cv2.COLOR_BGR2GRAY)\n",
    "#     faces = detector(gray)\n",
    "#     if not faces:\n",
    "#         return None\n",
    "#     shape = predictor(gray, faces[0])\n",
    "#     points = [(p.x, p.y) for p in shape.parts()] \n",
    "    \n",
    "#     # 添加12个辅助点（图像边界和身体关键点）\n",
    "#     h, w = img.shape[:2] \n",
    "#     points.extend([(0,0),  (w,0), (0,h), (w,h), (0,h//2), (w,h//2), \n",
    "#                   (w//4,h), (3*w//4,h), (w//2,0), (w//2,h), (0,7*h//8), (w,7*h//8)])\n",
    "#     return points\n",
    " \n",
    "# def delaunay_triangulation(points, img_shape):\n",
    "#     \"\"\"Delaunay三角剖分[11]()\"\"\"\n",
    "#     rect = (0, 0, img_shape[1], img_shape[0])\n",
    "#     subdiv = cv2.Subdiv2D(rect)\n",
    "#     for p in points:\n",
    "#         subdiv.insert(p) \n",
    "#     triangles = subdiv.getTriangleList() \n",
    "#     return triangles.reshape(-1,  3, 2).astype(np.int32) \n",
    " \n",
    "# def warp_triangle(img1, img2, tri1, tri2):\n",
    "#     \"\"\"三角形仿射变换对齐[11]()\"\"\"\n",
    "#     r1 = cv2.boundingRect(tri1) \n",
    "#     r2 = cv2.boundingRect(tri2) \n",
    "    \n",
    "#     # 提取三角形区域并仿射变换\n",
    "#     cropped1 = img1[r1[1]:r1[1]+r1[3], r1[0]:r1[0]+r1[2]]\n",
    "#     cropped2 = np.zeros_like(cropped1) \n",
    "    \n",
    "#     offset1 = tri1 - r1[:2]\n",
    "#     offset2 = tri2 - r2[:2]\n",
    "    \n",
    "#     mask = np.zeros((r1[3],  r1[2], 3), dtype=np.float32) \n",
    "#     cv2.fillConvexPoly(mask,  offset1, (1,1,1))\n",
    "    \n",
    "#     M = cv2.getAffineTransform(offset2.astype(np.float32),  offset1.astype(np.float32)) \n",
    "#     warped = cv2.warpAffine(img2[r2[1]:r2[1]+r2[3],  r2[0]:r2[0]+r2[2]], M, (r1[2], r1[3]))\n",
    "    \n",
    "#     # 融合三角形区域 \n",
    "#     img1[r1[1]:r1[1]+r1[3], r1[0]:r1[0]+r1[2]] = img1[r1[1]:r1[1]+r1[3], r1[0]:r1[0]+r1[2]] * (1-mask) + warped * mask \n",
    "#     return img1\n",
    " \n",
    "# def face_fusion(img1, img2, alpha=0.5):\n",
    "#     \"\"\"主融合函数\"\"\"\n",
    "#     # 1. 获取特征点 \n",
    "#     pts1 = get_landmarks(img1)\n",
    "#     pts2 = get_landmarks(img2)\n",
    "#     if pts1 is None:\n",
    "#         raise ValueError(\"未检测到人脸1\")\n",
    "#     if pts2 is None:\n",
    "#         raise ValueError(\"未检测到人脸2\")\n",
    "    \n",
    "#     # 2. 三角剖分 \n",
    "#     triangles = delaunay_triangulation(pts1, img1.shape) \n",
    "    \n",
    "#     # 3. 创建空白画布\n",
    "#     output = np.zeros_like(img1) \n",
    "    \n",
    "#     # 4. 逐三角形仿射变换 \n",
    "#     for tri in triangles:\n",
    "#         idx = [np.where((pts1 == tuple(p)).all(axis=1))[0][0] for p in tri]\n",
    "#         tri1 = np.array([pts1[i]  for i in idx])\n",
    "#         tri2 = np.array([pts2[i]  for i in idx])\n",
    "#         warp_triangle(output, img2, tri1, tri2)\n",
    "    \n",
    "#     # 5. 泊松融合消除边界[13]()\n",
    "#     center = (img1.shape[1]//2,  img1.shape[0]//2) \n",
    "#     result = cv2.seamlessClone(output,  img1, np.ones_like(img1[:,:,0])*255,  center, cv2.NORMAL_CLONE)\n",
    "    \n",
    "#     # 6. 透明度混合 \n",
    "#     return cv2.addWeighted(result,  alpha, img1, 1-alpha, 0)\n",
    " \n",
    "# # 使用示例 \n",
    "# img1 = cv2.imread(\"input.jpg\") \n",
    "# img2 = cv2.imread(\"style.png\") \n",
    "# result = face_fusion(img1, img2, alpha=0.7)\n",
    "# cv2.imwrite(\"pic.jpg\",  result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63b72dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "融合完成！结果已保存为 pic.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "from PIL import Image, ImageOps \n",
    " \n",
    "def preprocess_images(user_img_path, character_img_path):\n",
    "    # 读取图像\n",
    "    user_img_bgr = cv2.imread(user_img_path)\n",
    "    char_img_bgr = cv2.imread(character_img_path)\n",
    "    if user_img_bgr is None:\n",
    "        raise ValueError(f\"无法读取用户图片: {user_img_path}\")\n",
    "    if char_img_bgr is None:\n",
    "        raise ValueError(f\"无法读取角色图片: {character_img_path}\")\n",
    "    # 转为RGB\n",
    "    user_img = cv2.cvtColor(user_img_bgr,  cv2.COLOR_BGR2RGB)\n",
    "    char_img = cv2.cvtColor(char_img_bgr,  cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    # 人脸检测（使用OpenCV Haar级联）\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades  + 'haarcascade_frontalface_default.xml') \n",
    "    user_faces = face_cascade.detectMultiScale(user_img,  scaleFactor=1.1, minNeighbors=5)\n",
    "    \n",
    "    if len(user_faces) == 0:\n",
    "        raise ValueError(\"未检测到用户人脸，请提供清晰正面照片\")\n",
    "        \n",
    "    # 提取最大人脸区域 \n",
    "    x, y, w, h = max(user_faces, key=lambda rect: rect[2]*rect[3])\n",
    "    user_face = user_img[y:y+h, x:x+w]\n",
    "    \n",
    "    # 调整牛头人图像匹配人脸尺寸\n",
    "    char_img = cv2.resize(char_img,  (w, h))\n",
    "    return user_face, char_img \n",
    "\n",
    "def seamless_blending(user_face, char_img):\n",
    "    # 创建掩码（全白矩形）\n",
    "    mask = 126 * np.ones(char_img.shape,  char_img.dtype) \n",
    "    \n",
    "    # 计算融合中心点（人脸区域中心）\n",
    "    center = (user_face.shape[1]//2,  user_face.shape[0]//2) \n",
    "    \n",
    "    # 泊松融合 \n",
    "    blended = cv2.seamlessClone( \n",
    "        char_img, \n",
    "        user_face, \n",
    "        mask, \n",
    "        center, \n",
    "        cv2.NORMAL_CLONE \n",
    "    )\n",
    "    return blended \n",
    "\n",
    "# 输入文件路径\n",
    "user_img = \"input.jpg\" \n",
    "character_img = \"style.png\" \n",
    " \n",
    "try:\n",
    "    # 预处理与对齐\n",
    "    user_face, minotaur_resized = preprocess_images(user_img, character_img)\n",
    "    \n",
    "    # 融合处理 \n",
    "    result = seamless_blending(user_face, minotaur_resized)\n",
    "    \n",
    "    # 保存结果\n",
    "    Image.fromarray(result).save(\"pic.png\") \n",
    "    print(\"融合完成！结果已保存为 pic.png\") \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"处理失败: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288057b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfce967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
